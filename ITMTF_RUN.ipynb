{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of time slices with docs: 123\n",
      "Number of time slices: 123\n",
      "Number of time vocab: 12517\n",
      "Number of documents: 2673\n",
      "Number of unique tokens: 12517\n",
      "20\n",
      "Iteration start timee = 14:56:40\n",
      "initialrun0.sav saved for visualization\n",
      "Iteration Complete =  15:04:04\n",
      "Run Complete \n"
     ]
    }
   ],
   "source": [
    "%run load_helper.ipynb\n",
    "\n",
    "# ##################################################\n",
    "#             SET PARAMETERS\n",
    "#\n",
    "# pick a baseline\n",
    "#        baselines = [\"10topics\", \"15topics\", \"20topics\", \"25topics\", \"30topics\"]\n",
    "#\n",
    "# name your run (used to store the iterations); models will be saved myrun1.sav myrun2.save etc\n",
    "#\n",
    "# set your parameters\n",
    "# don't forget to set the number of topics for that baseline\n",
    "#\n",
    "# ##################################################\n",
    "runname = \"initialrun\"\n",
    "mybaseline = \"20topicsv\"\n",
    "num_topics = 20 # set this based upon baseline \n",
    "                # based on our analysis of coherence, 20 is a good starting number\n",
    "\n",
    "# below are default params that can be played with\n",
    "num_buffers = 5    # how many buffers to add each iteration\n",
    "lda_decay = .5     # how much the prior influences the iteration 0 - 1 \n",
    "num_iterations = 1 # the article used 5\n",
    "\n",
    "\n",
    "# ##################################################\n",
    "#\n",
    "# The ITMFT algorithm\n",
    "#\n",
    "#  Run cell 1\n",
    "#  and either cell 2 (to create a baseline)\n",
    "#      or cell 3 to load the baseline\n",
    "# ##################################################\n",
    "file_name = save_path + mybaseline + \".sav\"\n",
    "model = LdaModel.load(file_name)\n",
    "\n",
    "iteration = 0\n",
    "oldsignificanttopics = 0\n",
    "significanttopcs = 1\n",
    "\n",
    "while iteration < num_iterations and significanttopcs > oldsignificanttopics :\n",
    "    # create a topic coverage matrix preset to 0\n",
    "    topiccoverage = []\n",
    "    i = 0\n",
    "    while i < len(docs_per_timeslice) :\n",
    "        y = 0\n",
    "        thistopic = []\n",
    "        while y < num_topics:\n",
    "            thistopic.append(0.0)\n",
    "            y += 1\n",
    "        topiccoverage.append(thistopic)\n",
    "        i += 1\n",
    "            \n",
    "    # get the topic coverage per timeslice per doc\n",
    "    timeslice = 0\n",
    "    for timeslicedocs in docs_per_timeslice :\n",
    "        # for each doc in this timeslice\n",
    "        for doc in timeslicedocs :\n",
    "            # get the probability matrix\n",
    "            probs = model.get_document_topics(bow[doc])\n",
    "            #its a sparse array, prob[0] is the topic and prob[1] is the probabiltiy\n",
    "            for prob in probs :\n",
    "                topiccoverage[timeslice][prob[0]] += prob[1]\n",
    "        timeslice += 1\n",
    "        \n",
    "    topics = model.get_topics()\n",
    "    \n",
    "    newtopics = []\n",
    "    # ##################################################\n",
    "    # INPUT:\n",
    "    # timeslicetokencounts - we have the word coverage for each model token\n",
    "    # topiccoverage - and now we have the topic coverage\n",
    "    # topics - the current topic word probabilities\n",
    "    #\n",
    "    # OUTPUT:\n",
    "    # updated array newtopics = []\n",
    "    #\n",
    "    # run the iteration\n",
    "    # ##################################################\n",
    "    \n",
    "    #%run ITMTF_iterate.ipynb\n",
    "\n",
    "    \n",
    "    # ##################################################\n",
    "    #\n",
    "    # using the returned topics probabilies\n",
    "    # and adding buffers - num_buffers using bufferprob\n",
    "    # create the prior\n",
    "    # update num_topics\n",
    "    # and run the model\n",
    "    # ##################################################\n",
    "    \n",
    "    #$$$ remove this, for now just creating a topic prob list of X from old model as the return\n",
    "    topics = model.get_topics()\n",
    "    print(len(topics))\n",
    "    for topic in topics :\n",
    "        newtopics.append(topic)\n",
    "    #$$$ remove this, for now just creating a topic prob list of X from old model as the return\n",
    "        \n",
    "    # add the buffers\n",
    "    z = 0\n",
    "    while z < num_buffers:\n",
    "        newtopics.append(bufferprob)\n",
    "        z += 1\n",
    "    num_topics = len(newtopics)\n",
    "\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Iteration start timee =\", current_time)\n",
    "    model = LdaModel(\n",
    "        corpus=corpus,\n",
    "        id2word=tokentoword,\n",
    "        chunksize=chunksize,\n",
    "        alpha='auto',               \n",
    "        eta=newtopics,                 # preset topic/word\n",
    "        iterations=iterations,\n",
    "        num_topics=num_topics,         # added buffer topics\n",
    "        passes=passes,\n",
    "        decay = lda_decay,\n",
    "        eval_every=eval_every\n",
    "    )\n",
    "\n",
    "    file_name = runname + str(iteration) \n",
    "    path_name = save_path + file_name + \".sav\"\n",
    "    print(file_name + \" - saved for visualization\")\n",
    "    model.save(path_name )\n",
    " \n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Iteration Complete = \", current_time)\n",
    "\n",
    "    iteration += 1\n",
    "print(\"Run Complete \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Gensim",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

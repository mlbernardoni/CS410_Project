{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of time slices with docs: 123\n",
      "Number of time slices: 123\n",
      "Number of time vocab: 12517\n",
      "Number of documents: 2673\n",
      "Number of unique tokens: 12517\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import io\n",
    "import os.path\n",
    "import re\n",
    "import tarfile\n",
    "from datetime import datetime\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import smart_open\n",
    "\n",
    "# ##################################################\n",
    "#\n",
    "#  Always run this cell\n",
    "#\n",
    "#  and either cell 2 (to create a baseline)\n",
    "#      or cell 3 to load the baseline\n",
    "#\n",
    "# Before you run the iterations\n",
    "# ##################################################\n",
    "\n",
    "\n",
    "# ##################################################\n",
    "#             PARAMETERS TO PLAY WITH\n",
    "#\n",
    "# decay = used like μ in the algorithm (see notes below)\n",
    "# num_topics = number of topics to start with\n",
    "# num_iterations = max number of iterations to run the ITMTF algorithm\n",
    "# ##################################################\n",
    "\n",
    "\n",
    "# decay from 0 to 1, .5 - 1 guarenteed to converge\n",
    "# .5 is model's default\n",
    "# closer to 1, like a lower μ\n",
    "#      decay = 1 is like μ = 0\n",
    "lda_decay = .5    \n",
    "\n",
    "# number of topics to start with, per the article, 30 is a good start\n",
    "num_topics = 30\n",
    "num_buffers = 5   # how many buffers to add each iteration\n",
    "\n",
    "# max number of iterations to run - the article used 5\n",
    "num_iterations = 1\n",
    "\n",
    "# ##################################################\n",
    "#             Other parameters \n",
    "#  used to load the data\n",
    "#  or default values for the LDA algorithm\n",
    "# ##################################################\n",
    "#input parameters\n",
    "documents_path = \".\\\\LDA_data\\\\LDAreduced.csv\"\n",
    "vocab_path = \".\\\\LDA_data\\\\LDAwordseries.csv\"\n",
    "save_path = \".\\\\LDA_data\\\\\"\n",
    "\n",
    "# model parameters\n",
    "num_docs = 0\n",
    "num_words = 0\n",
    "chunksize = 2000\n",
    "passes = 100\n",
    "iterations = 400\n",
    "eval_every = None  # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "#docs = []\n",
    "#bow = []     # arrray of bow for doc, used to get probability\n",
    "\n",
    "#docs_per_timeslice = []\n",
    "\n",
    "#tokentoword = {}  # used to visualize the results of the model\n",
    "\n",
    "# as the model's vocab list is not in the same order as our predefined counts we will create these look up tables\n",
    "# how to use:\n",
    "#    use the timeslicevocabcounts list to run the ITMTF iteration  \n",
    "#      (index on the interation we are running)\n",
    "#      (the ITMFT algorithm will use the index of the count to represent each word)\n",
    "#    the ITMTF iteration will return new topic(s) using the index of the count array as a representative for the word \n",
    "#    use the index to find the model token with wordindextotoken\n",
    "#vocabtowordindex = {}     # dict of the preped vocabulary words to INDEX used to create wordindextotoken\n",
    "#wordindextotoken = {}     # will be used to get the model's token after each ITMFT iteration\n",
    "#timeslicevocabcounts = [] # an array of timeslices, each element contains an array of word counts for that timeslice\n",
    "\n",
    "\n",
    "# ##################################################\n",
    "# load the cleansed data into an array of docs\n",
    "# ##################################################\n",
    "docs = []\n",
    "with open(documents_path) as swf:\n",
    "    docs_per_timeslice = []\n",
    "    tempslice = []\n",
    "    count = 0\n",
    "    curtimeslice = \"2000.7.1\"\n",
    "    tempslice.append(curtimeslice)\n",
    "    curdocs = []\n",
    "    firstime = 0\n",
    "    for line in swf:\n",
    "        cells = line.split(',')\n",
    "        docslice = cells[0] + \".\" + cells[1] + \".\" + cells[2]\n",
    "        if firstime == 0 :\n",
    "            firstime = 1\n",
    "            curtimeslice = docslice\n",
    "        if docslice != curtimeslice :\n",
    "            curtimeslice = docslice\n",
    "            docs_per_timeslice.append(curdocs)\n",
    "            curdocs = []\n",
    "        curdocs.append(count) \n",
    "        count += 1\n",
    "        \n",
    "        docs.append(cells[3])\n",
    "    docs_per_timeslice.append(curdocs)\n",
    "swf.close\n",
    "print('Number of time slices with docs: %d' % len(docs_per_timeslice))\n",
    "\n",
    "# ##################################################\n",
    "# load the cleansed vocabulary into vocabtowordindex\n",
    "#      and timeslicevocabcounts\n",
    "# ##################################################\n",
    "# load the cleansed data into an array of docs\n",
    "header = 0\n",
    "timeslicevocabcounts = []\n",
    "vocabtowordindex = {}\n",
    "with open(vocab_path) as vwf:\n",
    "    for line in vwf:\n",
    "        linenumber = 1 # skip the header row\n",
    "        cells = line.split(',')\n",
    "        if header == 0 :\n",
    "            header = 1\n",
    "            i = 1 # skip header column\n",
    "            while i < len(cells) - 1:  # the cleansing process adds a black cell at the end\n",
    "                vocabtowordindex[cells[i]] = i-1  \n",
    "                #print(cells[i])\n",
    "                i += 1  \n",
    "        else :\n",
    "            wordcount = []\n",
    "            i = 1 # skip header column\n",
    "            while i < len(cells)-1:  # the cleansing process adds a black cell at the end\n",
    "                wordcount.append(cells[i])  # create an array of vocab counts at this timeslice\n",
    "                i += 1 \n",
    "            timeslicevocabcounts.append(wordcount)\n",
    "            \n",
    "vwf.close\n",
    "print('Number of time slices: %d' % len(timeslicevocabcounts))\n",
    "print('Number of time vocab: %d' % len(vocabtowordindex))\n",
    "\n",
    "# ##################################################\n",
    "# create the dictionary\n",
    "# ##################################################\n",
    "doctokens = [doc.split() for doc in docs]\n",
    "dictionary = Dictionary(doctokens)\n",
    "bow = []\n",
    "# Bag-of-words representation of the documents.\n",
    "for doc in doctokens :\n",
    "    bow.append(dictionary.doc2bow(doc))\n",
    "    \n",
    "    \n",
    "# ##################################################\n",
    "# create the corpus\n",
    "# ##################################################\n",
    "corpus = [dictionary.doc2bow(doc) for doc in doctokens]\n",
    "#print (corpus)\n",
    "\n",
    "num_docs = len(corpus)\n",
    "print('Number of documents: %d' % len(corpus))\n",
    "\n",
    "# ##################################################\n",
    "# create the wordindextotoken\n",
    "# a dict so we can take the word back from the iteration and find the dict index\n",
    "#   to put the probabilities in the right place\n",
    "# ##################################################\n",
    "wordindextotoken = {}\n",
    "i = 0\n",
    "while i < len(dictionary):  \n",
    "    wordindextotoken[vocabtowordindex[dictionary[i]]] = i\n",
    "    i += 1\n",
    "tokentoword = dictionary.id2token\n",
    "num_words = len(tokentoword)\n",
    "print('Number of unique tokens: %d' % len(tokentoword))\n",
    "\n",
    "# create a probabiltiy array for buffer topics that are added\n",
    "zeroprobs = []\n",
    "bufferprob = []\n",
    "i = 0\n",
    "while i < len(tokentoword) :\n",
    "    bufferprob.append(1/len(tokentoword))\n",
    "    zeroprobs.append(0.0)\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 18:35:54\n",
      "Model Finished\n",
      "Current Time = 18:45:21\n",
      ".\\LDA_data\\baseline.sav\n"
     ]
    }
   ],
   "source": [
    "# ##################################################\n",
    "#             Runs a baseline\n",
    "# ##################################################\n",
    "\n",
    "# Make a index to word dictionary.\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)\n",
    "\n",
    "model = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=tokentoword,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=num_topics,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every\n",
    ")\n",
    "\n",
    "print('Model Finished')\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)\n",
    "\n",
    "# ##################################################\n",
    "#             Saves the baseline\n",
    "# ##################################################\n",
    "\n",
    "file_name = save_path + \"baseline.sav\"\n",
    "print (file_name)\n",
    "model.save(file_name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################\n",
    "#             Loads the baseline\n",
    "# ##################################################\n",
    "file_name = save_path + \"baseline.sav\"\n",
    "model = LdaModel.load(file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "40\n",
      "[[5.0618539e+00 6.0041053e-08 3.7574844e+02 ... 6.0041053e-08\n",
      "  6.0041053e-08 6.0041053e-08]\n",
      " [1.6895573e-09 1.6895573e-09 3.4720972e-07 ... 1.6895573e-09\n",
      "  1.6895573e-09 1.6895573e-09]\n",
      " [2.1958781e-09 3.8222163e+00 2.8718840e+01 ... 2.1855671e-09\n",
      "  2.1855671e-09 2.1855671e-09]\n",
      " ...\n",
      " [7.9891346e-05 7.9891346e-05 4.0658543e+01 ... 7.9891346e-05\n",
      "  7.9891346e-05 7.9891346e-05]\n",
      " [7.9891346e-05 7.9891346e-05 7.9981313e-05 ... 7.9891346e-05\n",
      "  7.9891346e-05 7.9891346e-05]\n",
      " [7.9891346e-05 7.9891346e-05 7.9891346e-05 ... 7.9891346e-05\n",
      "  7.9891346e-05 7.9891346e-05]]\n",
      "Current Time = 19:55:46\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-bb27310ea49f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[0mcurrent_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%H:%M:%S\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Current Time =\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m     model = LdaModel(\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[0mcorpus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mid2word\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtokentoword\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gensim\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0muse_numpy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatcher\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunks_as_numpy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_numpy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minit_dir_prior\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gensim\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, corpus, chunksize, decay, offset, passes, update_every, eval_every, iterations, gamma_threshold, chunks_as_numpy)\u001b[0m\n\u001b[0;32m    978\u001b[0m                         \u001b[0mpass_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunk_no\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlencorpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    979\u001b[0m                     )\n\u001b[1;32m--> 980\u001b[1;33m                     \u001b[0mgammat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_estep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    981\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    982\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize_alpha\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gensim\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36mdo_estep\u001b[1;34m(self, chunk, state)\u001b[0m\n\u001b[0;32m    740\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    741\u001b[0m             \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 742\u001b[1;33m         \u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msstats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollect_sstats\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    743\u001b[0m         \u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msstats\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0msstats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    744\u001b[0m         \u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumdocs\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# avoids calling len(chunk) on a generator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gensim\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36minference\u001b[1;34m(self, chunk, collect_sstats)\u001b[0m\n\u001b[0;32m    691\u001b[0m                 \u001b[1;31m# Substituting the value of the optimal phi back into\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m                 \u001b[1;31m# the update for gamma gives this update. Cf. Lee&Seung 2001.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m                 \u001b[0mgammad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mexpElogthetad\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcts\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mphinorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpElogbetad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m                 \u001b[0mElogthetad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdirichlet_expectation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgammad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m                 \u001b[0mexpElogthetad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mElogthetad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ##################################################\n",
    "#\n",
    "# The ITMFT algorithm\n",
    "#\n",
    "#  Run cell 1\n",
    "#  and either cell 2 (to create a baseline)\n",
    "#      or cell 3 to load the baseline\n",
    "# ##################################################\n",
    "\n",
    "iteration = 0\n",
    "oldsignificanttopics = 0\n",
    "significanttopcs = 1\n",
    "\n",
    "while iteration < num_iterations and significanttopcs > oldsignificanttopics :\n",
    "    # create a topic coverage matrix preset to 0\n",
    "    topiccoverage = []\n",
    "    i = 0\n",
    "    while i < len(docs_per_timeslice) :\n",
    "        y = 0\n",
    "        thistopic = []\n",
    "        while y < num_topics:\n",
    "            thistopic.append(0.0)\n",
    "            y += 1\n",
    "        topiccoverage.append(thistopic)\n",
    "        i += 1\n",
    "            \n",
    "    # get the topic coverage per timeslice per doc\n",
    "    timeslice = 0\n",
    "    for timeslicedocs in docs_per_timeslice :\n",
    "        # for each doc in this timeslice\n",
    "        for doc in timeslicedocs :\n",
    "            # get the probability matrix\n",
    "            probs = model.get_document_topics(bow[doc])\n",
    "            #its a sparse array, prob[0] is the topic and prob[1] is the probabiltiy\n",
    "            for prob in probs :\n",
    "                topiccoverage[timeslice][prob[0]] += prob[1]\n",
    "        timeslice += 1\n",
    "        \n",
    "    # ##################################################\n",
    "    # timeslicevocabcounts - we have the word coverage \n",
    "    # topiccoverage - and now we have the topic coverage\n",
    "    #\n",
    "    # run the iteration\n",
    "    # ##################################################\n",
    "    #      $$$$$$$$$$$$$$$$$\n",
    "    #      ADD ALGORITHM HERE \n",
    "    #      RETURN A LIST OF newtopics = []\n",
    "    #          topic word probabilities\n",
    "    #      AND UPDATE THE VARIABLE significanttopcs\n",
    "    #\n",
    "    \n",
    "    # ##################################################\n",
    "    #\n",
    "    # using the returned topics probabilies\n",
    "    #    correct the words to the dictionary index\n",
    "    # and adding buffers - num_buffers using bufferprob\n",
    "    # create the prior\n",
    "    # update num_topics\n",
    "    # and run the model\n",
    "    # ##################################################\n",
    "    \n",
    "    #$$$ remove this, for now just creating a topic prob list of X from old model as the return\n",
    "    topics = model.get_topics()\n",
    "    print(len(topics))\n",
    "    newtopics = []\n",
    "    for topic in topics :\n",
    "        newtopics.append(topic)\n",
    "    mylambda = model.state.get_lambda()\n",
    "    print(len(mylambda))\n",
    "    print (mylambda)\n",
    "    #$$$ remove this, for now just creating a topic prob list of X from old model as the return\n",
    "        \n",
    "    # fix the words\n",
    "    # REMOVE COMMENTS WHEN ALGORITM IS PLUGGED IN $$$$$$\n",
    "    \"\"\" \n",
    "    inputtopics = []\n",
    "    for onetopic in newtopics :\n",
    "        index = 0\n",
    "        temptopic = zeroprobs\n",
    "        for wordprob in inputtopics :\n",
    "            temptopic[wordindextotoken.get(count)] = wordprob\n",
    "            count += 1\n",
    "        inputtopics.append(zeroprobs)\n",
    "    \"\"\"\n",
    "            \n",
    "    \n",
    "    # add the buffers\n",
    "    z = 0\n",
    "    while z < num_buffers:\n",
    "        newtopics.append(bufferprob)\n",
    "        z += 1\n",
    "    num_topics = len(newtopics)\n",
    "\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Current Time =\", current_time)\n",
    "    model = LdaModel(\n",
    "        corpus=corpus,\n",
    "        id2word=tokentoword,\n",
    "        chunksize=chunksize,\n",
    "        alpha='auto',               \n",
    "        eta=newtopics,                 # preset topic/word\n",
    "        iterations=iterations,\n",
    "        num_topics=num_topics,       # added a topic\n",
    "        passes=passes,\n",
    "        decay = lda_decay,\n",
    "        eval_every=eval_every\n",
    "    )\n",
    "\n",
    "    mylambda = model.state.get_lambda()\n",
    "    print(len(mylambda))\n",
    "    print (mylambda)\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Current Time =\", current_time)\n",
    "\n",
    "    iteration += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.26613462), (1, 0.031513344), (2, 0.07535973), (8, 0.17425913), (11, 0.19474572), (12, 0.079344586), (14, 0.12846163), (23, 0.032250945)]\n"
     ]
    }
   ],
   "source": [
    "probs = model.get_document_topics(bow[0])\n",
    "print (probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.0134544e+00 9.1549730e+00 7.7883820e+02 ... 3.3333335e-02\n",
      "  3.3333335e-02 3.3333335e-02]\n",
      " [3.3333335e-02 3.3333335e-02 1.7366159e+02 ... 3.3333335e-02\n",
      "  3.3333335e-02 3.3333335e-02]\n",
      " [3.3333335e-02 3.3333335e-02 2.5686323e+01 ... 3.3333335e-02\n",
      "  3.3333335e-02 3.3333335e-02]\n",
      " ...\n",
      " [3.3333335e-02 3.3333335e-02 9.0869951e+00 ... 3.3333335e-02\n",
      "  3.3333335e-02 3.3333335e-02]\n",
      " [3.3333335e-02 3.3333335e-02 7.4259033e+01 ... 3.3333335e-02\n",
      "  3.3333335e-02 3.3333335e-02]\n",
      " [5.4003153e+00 3.3333335e-02 2.3440340e+02 ... 3.3333335e-02\n",
      "  3.3333335e-02 3.3333335e-02]]\n",
      "Current Time = 16:58:09\n",
      "[[8.0471684e-05 1.8356158e-04 6.4066490e+01 ... 6.6834934e-07\n",
      "  6.6834934e-07 6.6834934e-07]\n",
      " [5.6854842e-06 5.6854842e-06 2.9620504e-02 ... 5.6854842e-06\n",
      "  5.6854842e-06 5.6854842e-06]\n",
      " [7.3313749e-06 7.3313749e-06 5.6494819e-03 ... 7.3313749e-06\n",
      "  7.3313749e-06 7.3313749e-06]\n",
      " ...\n",
      " [2.0620668e-05 2.0620668e-05 4.5938123e-02 ... 2.0620668e-05\n",
      "  2.0620668e-05 2.0620668e-05]\n",
      " [3.1441290e-04 1.9407071e-06 1.3647249e-02 ... 1.9407071e-06\n",
      "  1.9407071e-06 1.9407071e-06]\n",
      " [9.0576878e+00 2.1910958e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]]\n",
      "Current Time = 17:04:27\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "mylambda = newmodel.state.get_lambda()\n",
    "print (mylambda)\n",
    "\n",
    "\n",
    "topics = newmodel.get_topics()\n",
    "\n",
    "newtopics = []\n",
    "for topic in topics :\n",
    "    newtopics.append(topic)\n",
    "\n",
    "#lets add a new topic\n",
    "newprob = []\n",
    "i = 0\n",
    "while i < 12517 :\n",
    "    newprob.append(0)\n",
    "    i += 1\n",
    "newprob[0] = .5\n",
    "newprob[1] = .5\n",
    "\n",
    "\n",
    "newtopics.append(newprob)\n",
    "\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)\n",
    "it1model = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=tokentoword,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',               \n",
    "    eta=newtopics,                 # preset topic/word\n",
    "    iterations=iterations,\n",
    "    num_topics=num_topics+1,       # added a topic\n",
    "    passes=passes,\n",
    "    decay = .05,\n",
    "    eval_every=eval_every\n",
    ")\n",
    "\n",
    "mylambda = it1model.state.get_lambda()\n",
    "print (mylambda)\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_topics = model.top_topics(corpus) #, num_words=20)\n",
    "\n",
    "# Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n",
    "avg_topic_coherence = sum([t[1] for t in top_topics]) / num_topics\n",
    "print('Average topic coherence: %.4f.' % avg_topic_coherence)\n",
    "\n",
    "pprint(top_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylambda = it1model.state.get_lambda()\n",
    "print (mylambda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_file = datapath(\"baseline_model\")\n",
    "newmodel = LdaModel.load(temp_file)\n",
    "\n",
    "mylambda = newmodel.state.get_lambda()\n",
    "print (mylambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_file = datapath(\"baseline_model\")\n",
    "newmodel = LdaModel.load(temp_file)\n",
    "\n",
    "topics = model.get_topics()\n",
    "#print(topics[0])\n",
    "\n",
    "\n",
    "count = 0\n",
    "newtopics = []\n",
    "for topic in topics :\n",
    "    newtopics.append(topic)\n",
    "    count += 1\n",
    "#print(count)\n",
    "\n",
    "#lets add a new topic\n",
    "newprob = []\n",
    "i = 0\n",
    "while i < 12517 :\n",
    "    newprob.append(0)\n",
    "    i += 1\n",
    "newprob[0] = .5\n",
    "newprob[1] = .5\n",
    "print(tokentoword[0])\n",
    "print(tokentoword[1])\n",
    "newtopics.append(newprob)\n",
    "\n",
    "num_topics += 1\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)\n",
    "model = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=tokentoword,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',               \n",
    "    eta=newtopics,                 # preset topic/word\n",
    "    iterations=iterations,\n",
    "    num_topics=num_topics,       # added a topic\n",
    "    passes=passes,\n",
    "    eval_every=eval_every\n",
    ")\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_topics = model.top_topics(corpus) #, num_words=20)\n",
    "\n",
    "# Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n",
    "avg_topic_coherence = sum([t[1] for t in top_topics]) / num_topics\n",
    "print('Average topic coherence: %.4f.' % avg_topic_coherence)\n",
    "\n",
    "pprint(top_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model to disk.\n",
    "temp_file = datapath(\"it1_model\")\n",
    "model.save(temp_file)\n",
    "model.show_topic(30, 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp_file = datapath(\"baseline_model\")\n",
    "#newmodel = LdaModel.load(temp_file)\n",
    "#newmodel.show_topic(29, 50) # will blow up if 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of probs\n",
    "doctopic = {}\n",
    "count = 0\n",
    "for onebag in bow :\n",
    "    doctopic[count] = model.get_document_topics(onebag)\n",
    "    count += 1\n",
    "print ( len(doctopic))\n",
    "\n",
    "# get the doc list for this iteration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (doctopic[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Gensim",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
